---
title: "Statistical Analysis in Political Science II:\\newline More issues in modeling time series"
author: "JBrandon Duck-Mayr"
date: "`r quack::american_date_format(Sys.Date())`"
urlcolor: Blue
header-includes:
    - \newcommand{\setsep}{\setlength{\itemsep}{3pt}}
    - \newcommand{\setskip}{\setlength{\parskip}{3pt}}
    - \renewcommand{\tightlist}{\setsep\setskip}
    - \newcommand{\expectation}[1]{\ensuremath{\mathbb{E}\left[#1\right]}}
    - \newcommand{\pd}[2][]{\ensuremath{\frac{\partial{#1}}{\partial{#2}}}}
    - \DeclareMathOperator{\Var}{Var}
    - \DeclareMathOperator{\Cov}{Cov}
    - \newcommand{\variance}[1]{\ensuremath{\Var\left[#1\right]}}
    - \newcommand{\covariance}[1]{\ensuremath{\Cov\left[#1\right]}}
    - \DeclareMathOperator{\standarddeviation}{sd}
    - \DeclareMathOperator{\standarderror}{se}
    - \usepackage{siunitx}
output:
    quack::presentation:
        toc: false
        incremental: true
---

<!--
Topics:
* Prais-Winsten
* Cox Proportional Hazards
-->

## Time series issues and topics

. . .

- Linear regression for time series
  + Revised assumptions, stationarity, types of exogeneity, ...
  + Lagged predictors or outcomes
  + Serial autocorrelation, HAC standard errors
  + Prais-Winsten estimation
- Time series cross-sectional data
- Survival analysis

## Time series assumptions

\begin{itemize}
    \tightlist
    \item[TS1] Linearity in parameters (essentially the same as MLR1)
    \item[TS2] No perfect collinearity (essentially the same as MLR2)
    \item[TS3] Zero conditional mean: $\mathbb{E}\left(\varepsilon_t\mid\mathbf{X}\right) = 0, t = 1, 2, \dots n$
    \item[TS4] Homoscedasticity: $\text{Var}\left(\varepsilon_t\mid\mathbf{X}\right) = \text{Var}\left(\varepsilon_t\right) = \sigma^2, t = 1, 2, \dots, n$
    \item[TS5] No serial correlation: Conditional on $\mathbf{X}$, the errors in two time periods are uncorrelated: $\text{Cor}\left(\varepsilon_t,\varepsilon_s\mid\mathbf{X}\right) = 0,\,\forall\,\, t \neq s$
    \item[TS6] Normally distributed errors
\end{itemize}

## Time series assumptions

- Under assumptions TS1--TS3, OLS is unbiased
- If we have contemporaneous exogeneity instead of TS3, OLS is still consistent, but not unbiased
- Under assumptions TS1--TS5, we get the sampling variance of $\hat{\beta}$: $\text{Var}\left(\hat{\boldsymbol\beta}\mid\mathbf{X}\right) = \sigma^2\left(\mathbf{X'X}\right)^{-1}$ (same as in cross-sectional)
- Under assumptions TS1--TS5, $\hat{\sigma}^2 = \text{SSR}/df$ is an unbiased estimator of $\sigma^2$
- Under assumptions TS1--TS5, OLS is BLUE
- Under assumptions TS1--TS6, OLS estimators are normally distributed, and $t$ and $F$ statistics and usual confidence intervals are all valid

## Stationarity and weak dependence

. . .

- A process $\{x_t; t = 1, 2, \dots\}$ is **stationary** if the joint distribution of  $\left(x_t, x_{t+1}, \dots x_{t + m}\right)$ is the same as the joint distribution of $\left(x_{t+h}, x_{t+h+1}, \dots x_{t+h + m}\right)$ for all $t$, $m$, and $h$
- A stationary time series is a **weakly dependent** process "if $x_t$ and $x_{t+h}$ are 'almost independent' as $h$ increases without bound" (Wooldridge, 368)
- Weak dependence replaces random sampling for proving the LLN and CLT hold

## Time series assumptions

\begin{itemize}
    \tightlist
    \item[TS1'] Linearity, stationarity, and weak dependence
    \item[TS2'] No perfect collinearity
    \item[TS3'] Zero conditional mean: Explanatory variables are \textit{contemporaneously exogenous}; $\mathbb{E}\left(\varepsilon_t\mid\mathbf{x}_t\right) = 0$
    \item[TS4'] \textit{Contemporaneous} homoscedasticity: $\text{Var}\left(\varepsilon_t\mid\mathbf{x}_t\right) = \sigma^2$
    \item[TS5'] No serial correlation
\end{itemize}

## Time series assumptions

- Under TS1'--TS3', OLS is consistent
- Under TS1'--TS5', OLS estimator is asymptotically normally distributed and $t$ and $F$ statistics are asymptotically valid

## Time series assumptions

\begin{itemize}
    \tightlist
    \item[TS1'] Linearity, stationarity, and weak dependence
    \item[TS2'] No perfect collinearity
    \item[TS3'] Zero conditional mean: Explanatory variables are \textit{contemporaneously exogenous}; $\mathbb{E}\left(\varepsilon_t\mid\mathbf{x}_t\right) = 0$
    \item[TS4'] \textcolor{BurntOrange}{\textit{Contemporaneous} homoscedasticity: $\text{Var}\left(\varepsilon_t\mid\mathbf{x}_t\right) = \sigma^2$}
    \item[TS5'] \textcolor{BurntOrange}{No serial correlation}
\end{itemize}

## HAC standard errors

. . .

- Recall that with serially correlated errors, test statistics are no longer valid
- But we can construct Heteroskedasticity and Autocorrelation Consistent (HAC) standard errors
- For $\beta_j$:
  + Obtain $``\text{se}\left(\hat{\beta}_j\right)"$, $\hat{\sigma}^2$, and $\hat{u}$ for OLS
  + Regress $x_j$ on the remaining predictors with residuals $\hat{r}$
  + Calculate $\hat{a} = \hat{u} \odot \hat{r}$
  + For a truncation lag $g$, calculate $\hat{v} = \sum_{t=1}^n \hat{a}_t^2 + 2 \sum_{h=1}^g \left[1 - h/(g+1)\right]\left(\sum_{t=h+1}^n\hat{a}_t\hat{a}_{t-h}\right)$
  + Then $\text{se}\left(\hat{\beta}_j\right) = \left[``\text{se}\left(\hat{\beta}_j\right)"/\hat{\sigma}^2\right]^2\sqrt{\hat{v}}$

## HAC standard errors in R

- `sandwich::NeweyWest()` with `prewhite = FALSE` generates the variance covariance matrix
- You can pass that to the `vcov.` argument of `lmtest::coeftest()` or use it manually

## HAC standard errors in R

\footnotesize

```{r, message = FALSE}
library(sandwich)
library(lmtest)
form = formula(approve ~ lcpifood + lrgasprice + unemploy + X11.Sep + iraqinvade)
ols = lm(formula = form, data = wooldridge::approval)
coeftest(ols)
```

## HAC standard errors in R

\footnotesize

```{r, message = FALSE}
library(sandwich)
library(lmtest)
form = formula(approve ~ lcpifood + lrgasprice + unemploy + X11.Sep + iraqinvade)
ols = lm(formula = form, data = wooldridge::approval)
coeftest(ols, vcov. = NeweyWest(ols, lag = 1, prewhite = FALSE))
```

## HAC standard errors in R

\footnotesize

```{r, message = FALSE}
library(sandwich)
library(lmtest)
form = formula(approve ~ lcpifood + lrgasprice + unemploy + X11.Sep + iraqinvade)
ols = lm(formula = form, data = wooldridge::approval)
coeftest(ols, vcov. = NeweyWest(ols, lag = 4, prewhite = FALSE))
```

## HAC standard errors in R

\footnotesize

```{r, message = FALSE}
library(sandwich)
library(lmtest)
form = formula(approve ~ lcpifood + lrgasprice + unemploy + X11.Sep + iraqinvade)
ols = lm(formula = form, data = wooldridge::approval)
coeftest(ols, vcov. = NeweyWest(ols, lag = 8, prewhite = FALSE))
```

## Prais-Winsten estimation

. . .

- The problem: HAC standard errors can be unreasonably large
- A solution(?): Prais-Winsten estimation
  + A form of "feasible generalized least squares" (feasible GLS)
  + **Warning**: Requires *strict* exogeneity for consistency!!
- Start by assuming TS1--TS4 & that errors follow an AR(1) model,
  $$ u_t = \rho u_{t-1} + \varepsilon_t $$
- Consider the equation $$ y_t = \beta_0 + \beta_1 x_{t1} + \dots + \beta_k x_{tk} + u_t; $$ multiply the previous observation by $\rho$ & subtract it to get $$ \tilde{y}_t = (1 - \rho) \beta_0 + \beta_1 \tilde{x}_{t1} + \dots + \beta_k \tilde{x}_{tk} + \varepsilon_t $$ where $$ \tilde{y}_t = y_t - \rho y_{t-1}, \tilde{x}_{tk} = x_{tk} - \rho x_{(t-1)k} $$ are the **quasi-differenced data**.

## Prais-Winsten estimation

. . .

- Note that this means we have to drop the first observation\invisible<1-2>{,}
- unless we define $$ \tilde{y}_1 = (1 - \rho^2)^{1/2} \beta_0 + \beta_1 \tilde{x}_{11} + \dots + \beta_k \tilde{x}_{1k} + \tilde{\varepsilon}_1, $$ $$ \text{where } \tilde{Z}_1 = (1 - \rho^2)^{1/2} Z_1 $$
- Then $t$ and $F$ statistics are asymptotically valid
- **but**, we don't know $\rho$...
- but luckily using $\hat{\rho}$ doesn't affect the estimators' asymptotic distribution

## Prais-Winsten estimation

. . .

So, the procedure is

1. Run OLS of $y_t$ on $x_{t1}, \dots x_{tk}$ with residuals $\hat{u}_t$
2. Regress $\hat{u}_t$ on $\hat{u}_{t-1}$ to get $\hat{\rho}$
3. Run OLS on the quasi-differenced data
   - Then your $t$ and $F$ statistics are asymptotically valid
   - (assuming TS1--TS4 and strict exogeneity hold)
   - Your standard errors will be more efficient,
     but at the cost of stronger assumptions

## Survival analysis

. . .

- Sometimes we care most about *when* something happens
  + How long does it take to confirm a Supreme Court justice?
  + Why do military conflicts persist, or not?
  + How long can a Senator retain the floor?
- Some important terms:
  + Survival function: Probability of an event *not* happening before or at time $t$
  + Hazard function: Instantaneous risk of the event happening
  + Cumulative hazard function: Integral of hazard function

## Proportional Hazards

. . .

- Consider two hazard functions, $h_0\left(t\right)$ and $h_1\left(t\right)$
- If $h_1\left(t\right) = \psi h_0\left(t\right)$, for some positive constant $\psi$ and all $t \geq 0$, we say they are **proportional** hazard functions

## Log-rank test

. . .

We can test equality of survival functions with a **log-rank test**

```{r log-rank-example}
## (see Table 3.3 in BrostrÃ¶m 2012)
exdata = data.frame(
    group = rep(x = c("numbers", "letters"), each = 5),
    time  = c(4, 2, 6, 1, 3.5, 5, 3, 6, 1, 2.5),
    event = c(1, 0, 1, 1, 0, 1, 1, 0, 1, 0)
)
library(survival)
fit = coxph(Surv(time, event) ~ group, data = exdata)
summary(fit)$logtest
```

## Visually assessing proportional hazards

. . .

```{r proportional-example-plot-cat, warning=FALSE, eval = FALSE}
library(ggplot2)
library(ggfortify)
dat = eha::oldmort %>% mutate(sex = ifelse(sex == "female", 1,))
fit = survfit(
    Surv(enter, exit, event) ~ sex,
    data = eha::oldmort
)
autoplot(fit, xlim = c(60, NA)) + theme_bw()
```

## Visually assessing proportional hazards

```{r proportional-example-plot, warning=FALSE, height = 2, width = 3, out.width = "95%", fig.align = "center", echo = FALSE}
library(ggplot2)
library(ggfortify)
fit = survfit(
    Surv(enter, exit, event) ~ sex,
    data = eha::oldmort
)
autoplot(fit, xlim = c(60, NA)) + theme_bw()
```

## Building the Cox proportional hazards model

. . .

- Let $\beta = \log\left(\psi\right)$. Then $$ h_x\left(t\right) = \exp\left(\beta x\right) h_0\left(t\right) $$
- Now consider a data structure where each observation $i$ has $(t_{i0}, t_{i}, d_{i}, \mathbf{x}_i)$, representing the starting point, ending point, event indicator, and predictors respectively
- Model: $(t_{i0}, t_{i}, d_{i})$ is the response
- Interpretation: $$ \frac{h\left(t; x+1\right)}{h\left(t; x\right)} = \exp\left(\beta\right) $$
- Implementation:
  + Create a survival object; e.g. `Surv(time, event)`
  + Use `survival::coxph()`; e.g. `coxph(Surv(time, event) ~ group, data = exdata)`
  + Then there are various summary and plotting methods, demonstrated above

## Cox Proportional Hazards `summary()` example

\footnotesize

```{r coxph-summary-example}
fit = coxph(Surv(enter, exit, event) ~ sex, data = eha::oldmort)
summary(fit)
```

## Visualizing estimated survival time

```{r survival-time-plot-code, message = FALSE, eval = FALSE, warning=FALSE, height = 2, width = 3, out.width = "95%", fig.align = "center"}
library(survminer)
plot_dat = data.frame(sex = c("female", "male"))
plot_fit = survfit(fit, newdata = plot_dat)
ggsurvplot(plot_fit, data = plot_dat)
```

## Visualizing estimated survival time

```{r survival-time-plot, message = FALSE, echo = FALSE, warning=FALSE, height = 2, width = 3, out.width = "95%", fig.align = "center"}
library(survminer)
plot_dat = data.frame(sex = c("female", "male"))
plot_fit = survfit(fit, newdata = plot_dat)
ggsurvplot(plot_fit, data = plot_dat, xlim = c(60, NA))
```

## Time series cross-sectional data

. . .

- A full treatment of this topic is outside the scope of this course
- But this is an important type of data analysis in political science
- Often used for causal inference difference-in-differences design
  + **Warning**: There have been a lot of developments on this "recently"
  + One resource on that for the interested is Ruttenauer and Aksoy (2024): <https://arxiv.org/pdf/2402.09928.pdf>

## Some considerations

. . .

- unit effects
- panel-corrected standard errors
  + `psce::psce(lm(...))`
- lagged DV
- again, be wary of recent developments !!!
